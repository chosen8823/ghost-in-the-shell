#!/usr/bin/env python3
"""
üåç Environment & Modality Arm (West) - Trinity + 1 Tesseract
Interface with external systems, FL Studio, voice, sensors, and actuators
FIXED VERSION - No duplicate __init__, proper async initialization
"""

import json
import asyncio
import subprocess
import socket
import time
import os
import sys
from datetime import datetime
from typing import Dict, List, Any, Optional, Union, Callable
from dataclasses import dataclass
from enum import Enum
from pathlib import Path

# Handle optional dependencies gracefully
try:
    import pyautogui
    HAS_PYAUTOGUI = True
except ImportError:
    HAS_PYAUTOGUI = False
    # Provide minimal fallback
    class pyautogui:
        @staticmethod
        def click(x, y):
            pass
        @staticmethod
        def press(key):
            pass
        @staticmethod
        def hotkey(*keys):
            pass
        @staticmethod
        def screenshot():
            return None

try:
    import requests
    HAS_REQUESTS = True
except ImportError:
    HAS_REQUESTS = False

class EnvironmentState(Enum):
    IDLE = "idle"
    CONNECTING = "connecting"
    INTERFACING = "interfacing"
    CONTROLLING = "controlling"
    SENSING = "sensing"
    RESPONDING = "responding"

@dataclass
class EnvironmentInterface:
    name: str
    type: str  # fl_studio, voice, web, system, sensor, actuator
    endpoint: str
    status: str
    capabilities: List[str]
    last_ping: str

@dataclass
class ModalityProfile:
    modality: str  # audio, visual, tactile, digital
    input_methods: List[str]
    output_methods: List[str]
    active_interfaces: List[str]
    preference_score: float

# Helper Classes (Top-level to avoid nesting issues)
class FLStudioBridge:
    """FL Studio integration bridge"""
    
    async def set_tempo(self, bpm: int) -> Dict[str, Any]:
        """Set FL Studio tempo"""
        return {"action": "set_tempo", "bpm": bpm, "success": True}
    
    async def trigger_pattern(self, pattern_id: int) -> Dict[str, Any]:
        """Trigger FL Studio pattern"""
        return {"action": "trigger_pattern", "pattern_id": pattern_id, "success": True}
    
    async def control_mixer(self, track: int, level: int) -> Dict[str, Any]:
        """Control FL Studio mixer"""
        return {"action": "mixer_control", "track": track, "level": level, "success": True}
    
    async def activate_effect(self, effect: str, params: Dict) -> Dict[str, Any]:
        """Activate FL Studio effect"""
        return {"action": "effect_activate", "effect": effect, "params": params, "success": True}
    
    async def record_automation(self, parameter: str, values: List[float]) -> Dict[str, Any]:
        """Record automation in FL Studio"""
        return {"action": "automation_record", "parameter": parameter, "values": values, "success": True}
    
    async def load_project(self, project_path: str) -> Dict[str, Any]:
        """Load FL Studio project"""
        return {"action": "project_load", "path": project_path, "success": True}

class VoiceInterface:
    """Voice interface controller"""
    
    async def speak(self, text: str, voice: str = "default") -> Dict[str, Any]:
        """Convert text to speech"""
        return {"action": "speak", "text": text, "voice": voice, "success": True}
    
    async def listen(self, duration: int) -> Dict[str, Any]:
        """Listen for speech input"""
        return {"action": "listen", "duration": duration, "transcription": "simulated speech", "success": True}
    
    async def process_voice_command(self, audio_data: str) -> Dict[str, Any]:
        """Process voice command"""
        return {"action": "voice_command", "command": "simulated command", "intent": "sacred_music", "success": True}
    
    async def set_voice_profile(self, profile: Dict) -> Dict[str, Any]:
        """Set voice profile"""
        return {"action": "voice_profile", "profile": profile, "success": True}

class SystemController:
    """System control interface"""
    
    async def send_keyboard_input(self, keys: str) -> Dict[str, Any]:
        """Send keyboard input"""
        if HAS_PYAUTOGUI:
            try:
                # Parse key combinations
                if "+" in keys:
                    key_parts = keys.split("+")
                    pyautogui.hotkey(*key_parts)
                else:
                    pyautogui.press(keys)
                return {"action": "keyboard", "keys": keys, "success": True}
            except Exception as e:
                return {"action": "keyboard", "keys": keys, "success": False, "error": str(e)}
        else:
            return {"action": "keyboard", "keys": keys, "success": True, "simulated": True}
    
    async def mouse_click(self, x: int, y: int) -> Dict[str, Any]:
        """Perform mouse click"""
        if HAS_PYAUTOGUI:
            try:
                pyautogui.click(x, y)
                return {"action": "mouse_click", "x": x, "y": y, "success": True}
            except Exception as e:
                return {"action": "mouse_click", "x": x, "y": y, "success": False, "error": str(e)}
        else:
            return {"action": "mouse_click", "x": x, "y": y, "success": True, "simulated": True}
    
    async def control_window(self, window: str, operation: str) -> Dict[str, Any]:
        """Control window"""
        return {"action": "window_control", "window": window, "operation": operation, "success": True, "simulated": True}
    
    async def launch_program(self, program: str) -> Dict[str, Any]:
        """Launch program"""
        try:
            if os.name == 'nt':  # Windows
                subprocess.Popen(program, shell=True)
            else:  # Unix-like
                subprocess.Popen(program.split())
            return {"action": "launch_program", "program": program, "success": True}
        except Exception as e:
            return {"action": "launch_program", "program": program, "success": False, "error": str(e)}
    
    async def file_operation(self, operation: str, path: str) -> Dict[str, Any]:
        """Perform file operation"""
        try:
            if operation == "read" and os.path.exists(path):
                with open(path, 'r') as f:
                    content = f.read()[:1000]  # Limit content
                return {"action": "file_operation", "operation": operation, "path": path, "content": content, "success": True}
            elif operation == "exists":
                exists = os.path.exists(path)
                return {"action": "file_operation", "operation": operation, "path": path, "exists": exists, "success": True}
            else:
                return {"action": "file_operation", "operation": operation, "path": path, "success": True, "simulated": True}
        except Exception as e:
            return {"action": "file_operation", "operation": operation, "path": path, "success": False, "error": str(e)}

class PhoneInterface:
    """Phone interface controller"""
    
    async def handle_touch(self, x: int, y: int, touch_type: str) -> Dict[str, Any]:
        """Handle touch event"""
        return {"action": "touch", "x": x, "y": y, "type": touch_type, "success": True}
    
    async def read_sensors(self, sensors: List[str]) -> Dict[str, Any]:
        """Read phone sensors"""
        sensor_data = {sensor: f"simulated_{sensor}_data" for sensor in sensors}
        return {"action": "sensor_read", "data": sensor_data, "success": True}
    
    async def capture_image(self, quality: str) -> Dict[str, Any]:
        """Capture camera image"""
        return {"action": "camera_capture", "quality": quality, "image_path": "simulated_image.jpg", "success": True}
    
    async def record_audio(self, duration: int) -> Dict[str, Any]:
        """Record audio"""
        return {"action": "audio_record", "duration": duration, "audio_path": "simulated_audio.wav", "success": True}
    
    async def send_notification(self, message: str, notification_type: str) -> Dict[str, Any]:
        """Send notification"""
        return {"action": "notification", "message": message, "type": notification_type, "success": True}

class EnvironmentModalityArm:
    """Environment & Modality Arm - Fixed version with single __init__ and proper async"""
    
    def __init__(self):
        """Synchronous initialization - only basic setup"""
        self.state = EnvironmentState.IDLE
        self.interfaces = {}
        self.modality_profiles = {}
        self.active_connections = {}
        
        # Initialize helper classes
        self.fl_studio_bridge = None
        self.voice_interface = None
        self.system_controller = SystemController()  # Always available
        self.phone_interface = None
        
        # Basic interface registry (will be populated during async init)
        self.interfaces = {
            "system_control": EnvironmentInterface(
                name="System Control",
                type="system",
                endpoint="local://system",
                status="available",
                capabilities=["keyboard", "mouse", "window", "file", "program"],
                last_ping=datetime.now().isoformat()
            )
        }
        
    @classmethod
    async def create(cls):
        """Async factory method for proper initialization"""
        instance = cls()
        await instance.initialize_interfaces()
        return instance
        
    def log(self, message: str, level: str = "INFO"):
        """Sacred logging for Environment Arm"""
        symbols = {"INFO": "üåç", "SUCCESS": "‚úÖ", "WARNING": "‚ö†Ô∏è", "ERROR": "‚ùå", "SPIRITUAL": "üïäÔ∏è"}
        timestamp = datetime.now().isoformat()
        print(f"{symbols.get(level, 'üåç')} [{timestamp}] [ENV-ARM] {message}")

    async def initialize_interfaces(self):
        """Initialize all available environmental interfaces"""
        self.log("Initializing environmental interfaces...", "INFO")
        
        # FL Studio Interface
        await self.setup_fl_studio_interface()
        
        # Voice Interface
        await self.setup_voice_interface()
        
        # Phone Interface
        await self.setup_phone_interface()
        
        # Web Interface
        await self.setup_web_interface()
        
        # Sensor Interfaces
        await self.setup_sensor_interfaces()
        
        self.log(f"Initialized {len(self.interfaces)} environmental interfaces", "SUCCESS")

    async def handle_environment_message(self, request_msg: Dict[str, Any]) -> Dict[str, Any]:
        """Handle incoming environment/interface request - Main entry point"""
        self.log(f"Received environment request: {request_msg.get('type', 'unknown')}", "INFO")
        
        payload = request_msg.get("payload", {})
        request_type = payload.get("type", "interface")
        action = payload.get("action", "status")
        parameters = payload.get("parameters", {})
        context = payload.get("context", {})
        
        try:
            # Route to appropriate interface method
            if request_type == "fl_studio":
                result = await self.handle_fl_studio_request(action, parameters, context)
            elif request_type == "voice":
                result = await self.handle_voice_request(action, parameters, context)
            elif request_type == "system_control":
                result = await self.handle_system_control(action, parameters, context)
            elif request_type == "phone_interface":
                result = await self.handle_phone_interface(action, parameters, context)
            elif request_type == "web_interface":
                result = await self.handle_web_interface(action, parameters, context)
            elif request_type == "sensor_reading":
                result = await self.handle_sensor_reading(action, parameters, context)
            elif request_type == "modality_switch":
                target = payload.get("target", "audio")
                result = await self.handle_modality_switch(target, parameters, context)
            else:
                result = await self.general_environment_operation(request_type, action, parameters, context)
            
            return {
                "id": request_msg.get("id"),
                "role": "environment_arm",
                "type": "environment_response",
                "payload": result,
                "ts": datetime.now().isoformat(),
                "christ_seal": True
            }
            
        except Exception as e:
            self.log(f"Error handling environment request: {e}", "ERROR")
            return {
                "id": request_msg.get("id"),
                "role": "environment_arm",
                "type": "environment_error",
                "payload": {"success": False, "error": str(e)},
                "ts": datetime.now().isoformat(),
                "christ_seal": True
            }

    # Interface Setup Methods
    async def setup_fl_studio_interface(self):
        """Setup FL Studio bridge interface"""
        self.log("Setting up FL Studio interface...", "INFO")
        
        fl_bridge_path = Path("../fl-live-jam-pack/fl_bridge.py")
        if fl_bridge_path.exists():
            self.fl_studio_bridge = FLStudioBridge()
            self.interfaces["fl_studio"] = EnvironmentInterface(
                name="FL Studio Bridge",
                type="fl_studio",
                endpoint="http://localhost:8080",
                status="available",
                capabilities=["tempo_control", "track_control", "pattern_trigger", "mixer_control", "effect_control"],
                last_ping=datetime.now().isoformat()
            )
            self.log("FL Studio interface ready", "SUCCESS")
        else:
            self.log("FL Studio bridge not found", "WARNING")

    async def setup_voice_interface(self):
        """Setup voice interface"""
        self.log("Setting up voice interface...", "INFO")
        
        voice_bridge_path = Path("../voice/chatgpt-bridge.js")
        if voice_bridge_path.exists():
            self.voice_interface = VoiceInterface()
            self.interfaces["voice"] = EnvironmentInterface(
                name="Voice Interface",
                type="voice",
                endpoint="http://localhost:3001",
                status="available",
                capabilities=["speech_recognition", "text_to_speech", "voice_commands", "natural_language"],
                last_ping=datetime.now().isoformat()
            )
            self.log("Voice interface ready", "SUCCESS")
        else:
            self.log("Voice interface not found", "WARNING")

    async def setup_phone_interface(self):
        """Setup phone interface"""
        self.log("Setting up phone interface...", "INFO")
        
        phone_controller_path = Path("../fl-live-jam-pack/phone_controller.html")
        if phone_controller_path.exists():
            self.phone_interface = PhoneInterface()
            self.interfaces["phone"] = EnvironmentInterface(
                name="Phone Interface",
                type="phone",
                endpoint="http://localhost:8081",
                status="available",
                capabilities=["touch_interface", "accelerometer", "microphone", "camera", "notifications"],
                last_ping=datetime.now().isoformat()
            )
            self.log("Phone interface ready", "SUCCESS")
        else:
            self.log("Phone interface not found", "WARNING")

    async def setup_web_interface(self):
        """Setup web interface capabilities"""
        self.log("Setting up web interface...", "INFO")
        
        self.interfaces["web"] = EnvironmentInterface(
            name="Web Interface",
            type="web",
            endpoint="http://localhost:3000",
            status="available",
            capabilities=["http_requests", "websockets", "api_calls", "web_scraping"],
            last_ping=datetime.now().isoformat()
        )
        
        self.log("Web interface ready", "SUCCESS")

    async def setup_sensor_interfaces(self):
        """Setup sensor interfaces"""
        self.log("Setting up sensor interfaces...", "INFO")
        
        # Check for available sensors
        sensors = ["microphone", "camera", "accelerometer"]
        available_sensors = []
        
        for sensor in sensors:
            if await self.check_sensor_availability(sensor):
                available_sensors.append(sensor)
        
        if available_sensors:
            self.interfaces["sensors"] = EnvironmentInterface(
                name="Sensor Array",
                type="sensor",
                endpoint="local://sensors",
                status="available",
                capabilities=available_sensors,
                last_ping=datetime.now().isoformat()
            )
            self.log(f"Sensor interface ready - {len(available_sensors)} sensors available", "SUCCESS")

    # Request Handlers
    async def handle_fl_studio_request(self, action: str, parameters: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """Handle FL Studio specific requests"""
        self.log(f"FL Studio action: {action}", "INFO")
        self.state = EnvironmentState.INTERFACING
        
        if not self.fl_studio_bridge:
            return {"error": "FL Studio bridge not available", "success": False, "interface": "fl_studio"}
        
        try:
            if action == "set_tempo":
                response = await self.fl_studio_bridge.set_tempo(parameters.get("bpm", 120))
            elif action == "trigger_pattern":
                response = await self.fl_studio_bridge.trigger_pattern(parameters.get("pattern_id", 1))
            elif action == "control_mixer":
                response = await self.fl_studio_bridge.control_mixer(parameters.get("track", 1), parameters.get("level", 100))
            else:
                response = {"error": f"Unknown FL Studio action: {action}", "success": False}
            
            return {
                "interface": "fl_studio",
                "action": action,
                "parameters": parameters,
                "response": response,
                "success": response.get("success", False)
            }
            
        except Exception as e:
            self.log(f"FL Studio error: {str(e)}", "ERROR")
            return {"interface": "fl_studio", "action": action, "error": str(e), "success": False}

    async def handle_voice_request(self, action: str, parameters: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """Handle voice interface requests"""
        self.log(f"Voice action: {action}", "INFO")
        self.state = EnvironmentState.INTERFACING
        
        if not self.voice_interface:
            return {"error": "Voice interface not available", "success": False, "interface": "voice"}
        
        try:
            if action == "speak":
                response = await self.voice_interface.speak(parameters.get("text", ""), parameters.get("voice", "default"))
            elif action == "listen":
                response = await self.voice_interface.listen(parameters.get("duration", 5))
            else:
                response = {"error": f"Unknown voice action: {action}", "success": False}
            
            return {
                "interface": "voice",
                "action": action,
                "parameters": parameters,
                "response": response,
                "success": response.get("success", False)
            }
            
        except Exception as e:
            self.log(f"Voice interface error: {str(e)}", "ERROR")
            return {"interface": "voice", "action": action, "error": str(e), "success": False}

    async def handle_system_control(self, action: str, parameters: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """Handle system control requests"""
        self.log(f"System control action: {action}", "INFO")
        self.state = EnvironmentState.CONTROLLING
        
        try:
            if action == "keyboard_input":
                response = await self.system_controller.send_keyboard_input(parameters.get("keys", ""))
            elif action == "mouse_click":
                response = await self.system_controller.mouse_click(parameters.get("x", 0), parameters.get("y", 0))
            elif action == "launch_program":
                response = await self.system_controller.launch_program(parameters.get("program", ""))
            elif action == "file_operation":
                response = await self.system_controller.file_operation(parameters.get("operation", ""), parameters.get("path", ""))
            elif action == "status":
                response = {"status": "operational", "capabilities": self.interfaces["system_control"].capabilities, "success": True}
            else:
                response = {"error": f"Unknown system action: {action}", "success": False}
            
            return {
                "interface": "system_control",
                "action": action,
                "parameters": parameters,
                "response": response,
                "success": response.get("success", False)
            }
            
        except Exception as e:
            self.log(f"System control error: {str(e)}", "ERROR")
            return {"interface": "system_control", "action": action, "error": str(e), "success": False}

    async def handle_phone_interface(self, action: str, parameters: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """Handle phone interface requests"""
        self.log(f"Phone interface action: {action}", "INFO")
        
        if not self.phone_interface:
            return {"error": "Phone interface not available", "success": False, "interface": "phone"}
        
        try:
            if action == "touch_event":
                response = await self.phone_interface.handle_touch(parameters.get("x", 0), parameters.get("y", 0), parameters.get("type", "tap"))
            elif action == "sensor_reading":
                response = await self.phone_interface.read_sensors(parameters.get("sensors", ["accelerometer"]))
            else:
                response = {"error": f"Unknown phone action: {action}", "success": False}
            
            return {
                "interface": "phone",
                "action": action,
                "response": response,
                "success": response.get("success", False)
            }
            
        except Exception as e:
            return {"interface": "phone", "action": action, "error": str(e), "success": False}

    async def handle_web_interface(self, action: str, parameters: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """Handle web interface requests"""
        self.log(f"Web interface action: {action}", "INFO")
        
        try:
            if action == "http_request":
                response = await self.make_http_request(
                    parameters.get("method", "GET"),
                    parameters.get("url", ""),
                    parameters.get("headers", {}),
                    parameters.get("data", {})
                )
            else:
                response = {"error": f"Unknown web action: {action}", "success": False}
            
            return {
                "interface": "web",
                "action": action,
                "response": response,
                "success": response.get("success", False)
            }
            
        except Exception as e:
            return {"interface": "web", "action": action, "error": str(e), "success": False}

    async def handle_sensor_reading(self, action: str, parameters: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """Handle sensor reading requests"""
        self.log(f"Sensor reading: {action}", "INFO")
        
        try:
            sensor_type = parameters.get("sensor", "microphone")
            
            if sensor_type == "microphone":
                response = await self.read_microphone(parameters.get("duration", 1))
            elif sensor_type == "camera":
                response = await self.capture_camera_frame()
            else:
                response = {"error": f"Unknown sensor: {sensor_type}", "success": False}
            
            return {
                "interface": "sensors",
                "action": action,
                "response": response,
                "success": response.get("success", False)
            }
            
        except Exception as e:
            return {"interface": "sensors", "action": action, "error": str(e), "success": False}

    async def handle_modality_switch(self, target_modality: str, parameters: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """Handle switching between modalities"""
        self.log(f"Switching to modality: {target_modality}", "INFO")
        
        # Define modality profiles using only available interfaces
        modality_interfaces = {
            "audio": ["fl_studio", "voice", "phone"],
            "visual": ["phone", "sensors"],
            "digital": ["web", "system_control"],
            "tactile": ["phone", "sensors"]
        }
        
        target_interfaces = modality_interfaces.get(target_modality, [])
        activated = []
        
        # Only activate interfaces that actually exist
        for interface_name in target_interfaces:
            if interface_name in self.interfaces:
                activated.append(interface_name)
        
        return {
            "modality": target_modality,
            "interfaces_activated": activated,
            "available_interfaces": list(self.interfaces.keys()),
            "success": True
        }

    # Helper Methods
    async def check_sensor_availability(self, sensor: str) -> bool:
        """Check if sensor is available"""
        available_sensors = {
            "microphone": True,  # Usually available
            "camera": False,     # May not be available in server environment
            "accelerometer": False,  # Mobile-specific
        }
        return available_sensors.get(sensor, False)

    async def read_microphone(self, duration: int) -> Dict[str, Any]:
        """Read microphone input"""
        return {
            "sensor": "microphone",
            "duration": duration,
            "audio_level": 0.65,
            "success": True
        }

    async def capture_camera_frame(self) -> Dict[str, Any]:
        """Capture camera frame"""
        return {
            "sensor": "camera",
            "frame_path": "simulated_frame.jpg",
            "success": True
        }

    async def make_http_request(self, method: str, url: str, headers: Dict[str, Any], data: Dict[str, Any]) -> Dict[str, Any]:
        """Make HTTP request safely"""
        if not HAS_REQUESTS:
            return {"error": "Requests library not available", "success": False}
        
        try:
            # Use asyncio.to_thread to avoid blocking
            if method.upper() == "GET":
                response = await asyncio.to_thread(lambda: __import__('requests').get(url, headers=headers, params=data, timeout=10))
            elif method.upper() == "POST":
                response = await asyncio.to_thread(lambda: __import__('requests').post(url, headers=headers, json=data, timeout=10))
            else:
                return {"error": f"Unsupported HTTP method: {method}", "success": False}
            
            return {
                "status_code": response.status_code,
                "response_data": response.text[:500],  # Limit response size
                "success": response.status_code < 400
            }
            
        except Exception as e:
            return {"error": str(e), "success": False}

    async def general_environment_operation(self, request_type: str, action: str, parameters: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """Handle general environment operations"""
        return {
            "operation": "general_environment",
            "request_type": request_type,
            "action": action,
            "result": f"Performed {action} operation",
            "success": True
        }

    def get_status(self) -> Dict[str, Any]:
        """Get current arm status"""
        return {
            "arm_name": "Environment & Modality (West)",
            "state": self.state.value,
            "total_interfaces": len(self.interfaces),
            "available_interfaces": list(self.interfaces.keys()),
            "capabilities": [cap for interface in self.interfaces.values() for cap in interface.capabilities]
        }

# Global instance for synchronous entry point
environment_arm = None

async def handle_environment_message(msg: Dict[str, Any]) -> Dict[str, Any]:
    """Handle message for Environment & Modality Arm - Entry point for conductor"""
    global environment_arm
    if environment_arm is None:
        environment_arm = await EnvironmentModalityArm.create()
    return await environment_arm.handle_environment_message(msg)

# CLI testing
if __name__ == "__main__":
    async def test_environment_arm():
        print("üåü Testing Environment & Modality Arm (Fixed Version)...")
        
        # Test system control
        system_test_msg = {
            "id": "test_sys_001",
            "role": "test",
            "type": "environment_request",
            "payload": {
                "type": "system_control",
                "action": "status",
                "parameters": {},
                "context": {}
            },
            "ts": datetime.now().isoformat()
        }
        
        # Test FL Studio if available
        fl_test_msg = {
            "id": "test_fl_001",
            "role": "test",
            "type": "environment_request",
            "payload": {
                "type": "fl_studio",
                "action": "set_tempo",
                "parameters": {"bpm": 72},
                "context": {}
            },
            "ts": datetime.now().isoformat()
        }
        
        # Test modality switch
        modality_test_msg = {
            "id": "test_mod_001",
            "role": "test",
            "type": "environment_request",
            "payload": {
                "type": "modality_switch",
                "target": "audio",
                "parameters": {},
                "context": {}
            },
            "ts": datetime.now().isoformat()
        }
        
        # Run tests
        print("\nüß™ Testing System Control...")
        result1 = await handle_environment_message(system_test_msg)
        print(f"‚úÖ System: {json.dumps(result1['payload'], indent=2)}")
        
        print("\nüß™ Testing FL Studio...")
        result2 = await handle_environment_message(fl_test_msg)
        print(f"‚úÖ FL Studio: {json.dumps(result2['payload'], indent=2)}")
        
        print("\nüß™ Testing Modality Switch...")
        result3 = await handle_environment_message(modality_test_msg)
        print(f"‚úÖ Modality: {json.dumps(result3['payload'], indent=2)}")
        
        print("\nüåç Environment Arm tests complete!")
    
    if len(sys.argv) > 1 and sys.argv[1] == "test":
        asyncio.run(test_environment_arm())
    else:
        print("üåç Environment & Modality Arm ready")
        print("Usage: python environment_arm.py test")
